import streamlit as st
import os
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_chroma import Chroma
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain_core.documents import Document

# --- 1. CONFIGURACI√ìN DE TU PERFIL (BASE DE CONOCIMIENTO) ---
# Aqu√≠ est√° la informaci√≥n que la IA usar√° para responder.
INFO_JEFFERSSON = """
NOMBRE: Jeffersson Pretell
PERFIL: Estudiante de Econom√≠a (UNTRM) con especializaci√≥n en Ciencia de Datos, Estad√≠stica y Matem√°ticas Aplicadas.
OBJETIVO: Convertirse en Economista-Estad√≠stico-Programador y Data Scientist Full Stack.

HABILIDADES T√âCNICAS (STACK):
- Lenguajes: Python (avanzado), R/RStudio (avanzado), SQL.
- Big Data: Hadoop, Spark, PySpark.
- Cloud & DB: AWS, SQL Server, PostgreSQL, MongoDB, Databricks.
- Herramientas: Docker, Git/GitHub, Linux, Power BI.
- Web: Streamlit, Flask (B√°sico), HTML/CSS.

EXPERIENCIA Y PROYECTOS DESTACADOS:
1. Web Scraping Retail: Comparador de precios usando Python (Selenium/BeautifulSoup) para reducir asimetr√≠a de informaci√≥n.
2. Predicci√≥n de Fuga de Clientes (Churn): Modelo de Machine Learning usando PCA y Regresi√≥n Log√≠stica desplegado en Streamlit.
3. Detecci√≥n de Rostros: Script de visi√≥n artificial con OpenCV.
4. Automatizaci√≥n WhatsApp: Bot de env√≠o masivo para marketing usando Selenium.
5. Detecci√≥n de Fraudes: Modelo supervisado para tarjetas de cr√©dito con Scikit-learn.

EDUCACI√ìN:
- Universidad Nacional de Trujillo (Econom√≠a, VII Ciclo).
- Datacamp (Data Scientist Career Track).
- GEM (Especializaci√≥n Ingenier√≠a de Datos).
- Udacity & AWS (Nanodegree AI Scientist - Beca).
- Universidad Nacional de Ingenier√≠a (Cloud Computing y ML).

INTERESES:
- Inteligencia Artificial Generativa, NLP, Modelos Econ√≥micos, Econometr√≠a.
- "Conectar modelos econ√≥micos y tecnolog√≠a no es el futuro, es el presente".
"""

# --- 2. CONFIGURACI√ìN DE LA APP STREAMLIT ---
st.set_page_config(page_title="Jeffersson AI", layout="wide")

# Ocultar elementos propios de Streamlit para que se vea limpio en el iframe
hide_st_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            header {visibility: hidden;}
            .stApp { padding-top: 0; }
            </style>
            """
st.markdown(hide_st_style, unsafe_allow_html=True)

st.title("ü§ñ Chat con Jeffersson AI")
st.markdown("Soy un agente entrenado con el perfil profesional de Jeffersson. ¬°Preg√∫ntame lo que quieras!")

# --- 3. GESTI√ìN DE API KEY ---
# Para pruebas locales, pedimos la clave si no est√° en variables de entorno
if "OPENAI_API_KEY" not in os.environ:
    api_key = st.text_input("üîë Ingresa tu OpenAI API Key para probar:", type="password")
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
    else:
        st.info("Por favor ingresa una API Key de OpenAI para continuar.")
        st.stop()

# --- 4. L√ìGICA RAG (SOLO SE EJECUTA UNA VEZ) ---
@st.cache_resource
def setup_rag_chain():
    # A. Crear Documento
    docs = [Document(page_content=INFO_JEFFERSSON)]
    
    # B. Dividir texto (Chunking)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
    splits = text_splitter.split_documents(docs)
    
    # C. Vector Store (Base de datos en memoria)
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)
    retriever = vectorstore.as_retriever()
    
    # D. Modelo LLM
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
    
    # E. Prompt del Sistema
    system_prompt = (
        "Eres el asistente virtual del portafolio de Jeffersson Pretell. "
        "Responde preguntas sobre su experiencia y habilidades bas√°ndote ESTRICTAMENTE "
        "en el contexto proporcionado. "
        "S√© profesional, conciso y amable. Si no sabes algo, di que no tienes esa informaci√≥n. "
        "Responde siempre en primera persona como si fueras su asistente digital. "
        "\n\n"
        "Contexto: {context}"
    )
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}"),
    ])
    
    question_answer_chain = create_stuff_documents_chain(llm, prompt)
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)
    return rag_chain

rag_chain = setup_rag_chain()

# --- 5. INTERFAZ DE CHAT ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar historial
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input de usuario
if prompt := st.chat_input("Ej: ¬øQu√© experiencia tiene Jeffersson con Python?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            response = rag_chain.invoke({"input": prompt})
            answer = response["answer"]
            st.markdown(answer)
    
    st.session_state.messages.append({"role": "assistant", "content": answer})